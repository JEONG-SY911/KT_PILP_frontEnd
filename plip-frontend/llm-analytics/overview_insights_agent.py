####### Overview ì‹¤ìš©ì  ì¸ì‚¬ì´íŠ¸ ìƒì„± Agent #######
## LangGraphë¥¼ í™œìš©í•œ ë‹¨ê³„ë³„ ë¶„ì„ ë° ì‹¤ìš©ì  ì¡°ì–¸ ìƒì„±

import pandas as pd
import numpy as np
import os
import random
from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from datetime import datetime
from typing import List, Dict, Any, Literal, TypedDict
import json
import logging
import warnings
from dotenv import load_dotenv

# .env íŒŒì¼ ë¡œë“œ
load_dotenv()

warnings.filterwarnings("ignore", category=DeprecationWarning)

from typing import Annotated, Literal, Sequence, TypedDict, List, Dict
from langchain import hub
from langchain_core.messages import BaseMessage, HumanMessage
from langchain_core.output_parsers import StrOutputParser
from langchain_core.prompts import ChatPromptTemplate
from langchain_openai import ChatOpenAI
from langchain_community.embeddings import OpenAIEmbeddings
from langchain_community.vectorstores import Chroma
from langchain.output_parsers import CommaSeparatedListOutputParser
from langgraph.graph import StateGraph, END

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# í™˜ê²½ë³€ìˆ˜ì—ì„œ ì„¤ì • ë¡œë“œ
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
HOST = os.getenv("HOST", "0.0.0.0")
PORT = int(os.getenv("PORT", "8003"))
ENVIRONMENT = os.getenv("ENVIRONMENT", "development")

# API í‚¤ í™•ì¸
if not OPENAI_API_KEY:
    logger.error("OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .env íŒŒì¼ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
    raise ValueError("OPENAI_API_KEYê°€ í•„ìš”í•©ë‹ˆë‹¤.")

logger.info(f"Overview Insights Agent ì„œë²„ í™˜ê²½: {ENVIRONMENT}")
logger.info(f"OpenAI API í‚¤ ì„¤ì •ë¨: {'*' * 10}{OPENAI_API_KEY[-4:] if OPENAI_API_KEY else 'None'}")

app = FastAPI(title="Overview ì‹¤ìš©ì  ì¸ì‚¬ì´íŠ¸ ìƒì„± API", version="1.0.0")

# CORS ì„¤ì •
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # ì„ì‹œë¡œ ëª¨ë“  origin í—ˆìš©
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

## 1. State ì •ì˜ ---------------------------------------------
class OverviewInsightsState(TypedDict):
    dong_name: str
    population_data: Dict[str, Any]
    time_stats: List[Dict[str, Any]]
    gender_stats: Dict[str, Any] 
    age_stats: Dict[str, Any]
    
    # ë‹¨ê³„ë³„ ë¶„ì„ ê²°ê³¼
    traffic_analysis: str      # êµí†µ í˜¼ì¡ ì‹œê°„ëŒ€ ë¶„ì„
    dining_analysis: str       # ì‹ë‹¹ ë©”ë‰´ ì¶”ì²œ ë¶„ì„
    business_analysis: str     # ì‚¬ì—… ì•„ì´í…œ ì¶”ì²œ ë¶„ì„
    lifestyle_analysis: str    # ìƒí™œ íŒ¨í„´ ë¶„ì„
    
    # ìµœì¢… ê²°ê³¼
    overview_insights: List[Dict[str, str]]  # [{type: "traffic", content: "..."}, ...]
    current_step: str

## 2. LangGraph Agent ë…¸ë“œë“¤ ---------------------------------------------

def analyze_traffic_patterns(state: OverviewInsightsState) -> OverviewInsightsState:
    """êµí†µ í˜¼ì¡ ì‹œê°„ëŒ€ ë¶„ì„"""
    dong_name = state.get("dong_name", "")
    time_stats = state.get("time_stats", [])
    
    llm = ChatOpenAI(model="gpt-4o-mini")
    
    # ì‹œê°„ëŒ€ë³„ ì¸êµ¬ ë°ì´í„° ì¤€ë¹„ (Double íƒ€ì… ì²˜ë¦¬)
    time_data_text = ""
    if time_stats and len(time_stats) > 0:
        sorted_times = sorted(time_stats, key=lambda x: float(x.get('totalPopulation', 0)), reverse=True)
        top_3_busy = sorted_times[:3]
        time_data_text = ", ".join([f"{t.get('timeRange', 'N/A')}ì‹œ({int(float(t.get('totalPopulation', 0))):,}ëª…)" for t in top_3_busy])
    
    prompt = ChatPromptTemplate.from_template("""
ë‹¹ì‹ ì€ ë„ì‹œ êµí†µ íŒ¨í„´ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
{dong_name}ì˜ ì‹œê°„ëŒ€ë³„ ì¸êµ¬ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ êµí†µ í˜¼ì¡ ì‹œê°„ëŒ€ë¥¼ ë¶„ì„í•´ì£¼ì„¸ìš”.

ì‹œê°„ëŒ€ë³„ ì¸êµ¬ ë°ì´í„° (ìƒìœ„ 3ê°œ): {time_data}

êµ¬ì²´ì ì¸ ì´ìœ  ì˜ˆì‹œ:
- ì¶œê·¼/í‡´ê·¼ ëŸ¬ì‹œì•„ì›Œ
- ìƒì—…ì§€ì—­ íŠ¹ì„±ìƒ ì‡¼í•‘ê° ìœ ì…
- ì¸ê·¼ ì‚¬ë¬´ë¹Œë”©/í•™êµì˜ í™œë™ ì‹œê°„
- ì‹ë‹¹ê°€ ì´ìš©ê° ì§‘ì¤‘ ì‹œê°„

ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ **5ì¤„ ì´ë‚´**ë¡œ ê°„ê²°í•˜ê²Œ ë‹µë³€í•´ì£¼ì„¸ìš”:
"êµí†µì´ ê°€ì¥ í˜¼ì¡í•œ ì‹œê°„ëŒ€ëŠ” "XX"ì‹œ ì…ë‹ˆë‹¤. ì´ëŠ” [êµ¬ì²´ì ì¸ ì´ìœ  1-2ê°€ì§€]ë¡œ ì¸í•´ ëŒ€ì¤‘êµí†µ ì´ìš©ëŸ‰ê³¼ ë„ë¡œ êµí†µëŸ‰ì´ ê¸‰ì¦í•˜ëŠ” ì‹œê°„ëŒ€ì…ë‹ˆë‹¤."
""")
    
    formatted_prompt = prompt.format(
        dong_name=dong_name,
        time_data=time_data_text or "ë°ì´í„° ì—†ìŒ"
    )
    
    response = llm.invoke(formatted_prompt)
    traffic_analysis = response.content.strip()
    
    logger.info(f"êµí†µ ë¶„ì„ ì™„ë£Œ: {traffic_analysis[:50]}...")
    
    return {
        **state,
        "traffic_analysis": traffic_analysis,
        "current_step": "traffic_completed"
    }

def analyze_dining_recommendations(state: OverviewInsightsState) -> OverviewInsightsState:
    """ì‹ë‹¹ ë©”ë‰´ ì¶”ì²œ ë¶„ì„"""
    dong_name = state.get("dong_name", "")
    time_stats = state.get("time_stats", [])
    gender_stats = state.get("gender_stats", {})
    age_stats = state.get("age_stats", [])
    
    llm = ChatOpenAI(model="gpt-4o-mini")
    
    # ì ì‹¬/ì €ë… ì‹œê°„ëŒ€ ë°ì´í„° ì¶”ì¶œ (Double íƒ€ì… ì²˜ë¦¬)
    lunch_data = [t for t in time_stats if any(hour in t.get('timeRange', '') for hour in ['11', '12', '13'])]
    dinner_data = [t for t in time_stats if any(hour in t.get('timeRange', '') for hour in ['17', '18', '19', '20', '21', '22'])]
    
    lunch_population = sum([float(t.get('totalPopulation', 0)) for t in lunch_data])
    dinner_population = sum([float(t.get('totalPopulation', 0)) for t in dinner_data])
    
    # ì„±ë³„/ì—°ë ¹ ì •ë³´ (Double íƒ€ì… ì²˜ë¦¬)
    male_count = float(gender_stats.get('male', 0))
    female_count = float(gender_stats.get('female', 0))
    total_count = float(gender_stats.get('total', 1)) if gender_stats.get('total', 0) > 0 else 1
    
    male_ratio = round(male_count / total_count * 100, 1)
    female_ratio = round(female_count / total_count * 100, 1)
    
    prompt = ChatPromptTemplate.from_template("""
ë‹¹ì‹ ì€ ì™¸ì‹ì—…ê³„ íŠ¸ë Œë“œ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
{dong_name}ì˜ ì¸êµ¬ êµ¬ì„±ê³¼ ì‹ì‚¬ ì‹œê°„ëŒ€ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì¸ê¸° ë©”ë‰´ë¥¼ ì˜ˆì¸¡í•´ì£¼ì„¸ìš”.

ë°ì´í„°:
- ì ì‹¬ì‹œê°„(11-13ì‹œ) ìœ ë™ì¸êµ¬: {lunch_pop:,}ëª…
- ì €ë…ì‹œê°„(17-22ì‹œ) ìœ ë™ì¸êµ¬: {dinner_pop:,}ëª…  
- ì„±ë³„ ë¹„ìœ¨: ë‚¨ì„± {male_ratio}%, ì—¬ì„± {female_ratio}%
- ì§€ì—­ íŠ¹ì„±: {dong_name}

ë©”ë‰´ ì„ íƒ ì‹œ ê³ ë ¤ì‚¬í•­:
- ì„±ë³„ ë¹„ìœ¨ì— ë”°ë¥¸ ì„ í˜¸ë„
- ì§ì¥ì¸/í•™ìƒ/ì£¼ë¶€ ë“± ì£¼ ê³ ê°ì¸µ
- ì§€ì—­ íŠ¹ì„± (ìƒì—…ì§€/ì£¼ê±°ì§€/ì˜¤í”¼ìŠ¤ê°€)
- ê°€ê²©ëŒ€ì™€ ì ‘ê·¼ì„±
- ë°°ë‹¬/í¬ì¥ ê°€ëŠ¥ì„±

ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ **5ì¤„ ì´ë‚´**ë¡œ ê°„ê²°í•˜ê²Œ ë‹µë³€í•´ì£¼ì„¸ìš”:
"(ì„±ë³„, ë‚˜ì´ëŒ€ë¥¼ ê³ ë ¤í•˜ì—¬) ê°€ì¥ ì¸ê¸°ìˆì„ ê²ƒ ê°™ì€ ì ì‹¬(11ì‹œ~13ì‹œ) ë©”ë‰´ëŠ” "XXX"ì´ê³  ì €ë…(17ì‹œ~22ì‹œ) ë©”ë‰´ëŠ” "XXX"ì…ë‹ˆë‹¤. ì ì‹¬ ë©”ë‰´ ì„ íƒ ì´ìœ ëŠ” [êµ¬ì²´ì  ì´ìœ  1-2ê°€ì§€], ì €ë… ë©”ë‰´ ì„ íƒ ì´ìœ ëŠ” [êµ¬ì²´ì  ì´ìœ  1-2ê°€ì§€]ì…ë‹ˆë‹¤."
""")
    
    formatted_prompt = prompt.format(
        dong_name=dong_name,
        lunch_pop=int(lunch_population),
        dinner_pop=int(dinner_population),
        male_ratio=male_ratio,
        female_ratio=female_ratio
    )
    
    response = llm.invoke(formatted_prompt)
    dining_analysis = response.content.strip()
    
    logger.info(f"ì‹ë‹¹ ë©”ë‰´ ë¶„ì„ ì™„ë£Œ: {dining_analysis[:50]}...")
    
    return {
        **state,
        "dining_analysis": dining_analysis,
        "current_step": "dining_completed"
    }

def analyze_business_opportunities(state: OverviewInsightsState) -> OverviewInsightsState:
    """ì‚¬ì—… ì•„ì´í…œ ì¶”ì²œ ë¶„ì„"""
    dong_name = state.get("dong_name", "")
    population_data = state.get("population_data", {})
    time_stats = state.get("time_stats", [])
    gender_stats = state.get("gender_stats", {})
    
    llm = ChatOpenAI(model="gpt-4o-mini")
    
    # í”¼í¬ ì‹œê°„ëŒ€ ë¶„ì„ (Double íƒ€ì… ì²˜ë¦¬)
    peak_times = sorted(time_stats, key=lambda x: float(x.get('totalPopulation', 0)), reverse=True)[:2]
    peak_info = ", ".join([f"{t.get('timeRange', 'N/A')}ì‹œ" for t in peak_times])
    
    # ì™¸êµ­ì¸ ë¹„ìœ¨ (Double íƒ€ì… ì²˜ë¦¬)
    total_pop = float(population_data.get('total', 1)) if population_data.get('total', 0) > 0 else 1
    long_foreigner = float(population_data.get('longForeigner', 0))
    temp_foreigner = float(population_data.get('tempForeigner', 0))
    foreigner_ratio = round((long_foreigner + temp_foreigner) / total_pop * 100, 1)
    
    prompt = ChatPromptTemplate.from_template("""
ë‹¹ì‹ ì€ ì°½ì—… ì»¨ì„¤íŒ… ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
{dong_name}ì˜ ì¸êµ¬ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìœ ë§í•œ ì‚¬ì—… ì•„ì´í…œì„ ì¶”ì²œí•´ì£¼ì„¸ìš”.

ë°ì´í„°:
- ì´ ì¸êµ¬: {total:,}ëª…
- ì™¸êµ­ì¸ ë¹„ìœ¨: {foreigner_ratio}%
- ì„±ë³„ ë¹„ìœ¨: ë‚¨ì„± {male_ratio}%, ì—¬ì„± {female_ratio}%
- ì£¼ìš” í™œë™ ì‹œê°„ëŒ€: {peak_times}
- ì§€ì—­: {dong_name}

ê³ ë ¤ ìš”ì†Œ:
- ì¸êµ¬ ë°€ë„ì™€ ìœ ë™ì¸êµ¬
- ì„±ë³„/ì—°ë ¹ êµ¬ì„±
- ì™¸êµ­ì¸ ë¹„ìœ¨ (ë‹¤ë¬¸í™” ì„œë¹„ìŠ¤ í•„ìš”ì„±)
- í”¼í¬ ì‹œê°„ëŒ€ (ì„œë¹„ìŠ¤ ì‹œê°„ ìµœì í™”)
- ì§€ì—­ íŠ¹ì„± (ìƒì—…/ì£¼ê±°/ì—…ë¬´)

ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ **5ì¤„ ì´ë‚´**ë¡œ ê°„ê²°í•˜ê²Œ ë‹µë³€í•´ì£¼ì„¸ìš”:
"ì´ ì§€ì—­ì—ì„œ ê°€ì¥ ìœ ë§í•œ ì‚¬ì—… ì•„ì´í…œì€ "XXXì—…ì¢…"ì…ë‹ˆë‹¤. ì¶”ì²œ ì´ìœ ëŠ” [êµ¬ì²´ì  ê·¼ê±° 2-3ê°€ì§€]ì´ë©°, íŠ¹íˆ [íƒ€ê²Ÿ ê³ ê°ì¸µ]ì„ ëŒ€ìƒìœ¼ë¡œ í•œ [êµ¬ì²´ì  ì„œë¹„ìŠ¤/ìƒí’ˆ]ì´ ì„±ê³µ ê°€ëŠ¥ì„±ì´ ë†’ìŠµë‹ˆë‹¤."
""")
    
    male_ratio = round(float(gender_stats.get('male', 0)) / total_pop * 100, 1)
    female_ratio = round(float(gender_stats.get('female', 0)) / total_pop * 100, 1)
    
    formatted_prompt = prompt.format(
        dong_name=dong_name,
        total=int(total_pop),
        foreigner_ratio=foreigner_ratio,
        male_ratio=male_ratio,
        female_ratio=female_ratio,
        peak_times=peak_info
    )
    
    response = llm.invoke(formatted_prompt)
    business_analysis = response.content.strip()
    
    logger.info(f"ì‚¬ì—… ì•„ì´í…œ ë¶„ì„ ì™„ë£Œ: {business_analysis[:50]}...")
    
    return {
        **state,
        "business_analysis": business_analysis,
        "current_step": "business_completed"
    }

def analyze_lifestyle_patterns(state: OverviewInsightsState) -> OverviewInsightsState:
    """ìƒí™œ íŒ¨í„´ ë¶„ì„"""
    dong_name = state.get("dong_name", "")
    time_stats = state.get("time_stats", [])
    population_data = state.get("population_data", {})
    
    llm = ChatOpenAI(model="gpt-4o-mini")
    
    # ì‹œê°„ëŒ€ë³„ íŒ¨í„´ ë¶„ì„ (Double íƒ€ì… ì²˜ë¦¬)
    morning_pop = sum([float(t.get('totalPopulation', 0)) for t in time_stats if any(h in t.get('timeRange', '') for h in ['06', '07', '08', '09'])])
    afternoon_pop = sum([float(t.get('totalPopulation', 0)) for t in time_stats if any(h in t.get('timeRange', '') for h in ['14', '15', '16'])])
    night_pop = sum([float(t.get('totalPopulation', 0)) for t in time_stats if any(h in t.get('timeRange', '') for h in ['22', '23', '00', '01'])])
    
    prompt = ChatPromptTemplate.from_template("""
ë‹¹ì‹ ì€ ë„ì‹œ ìƒí™œ íŒ¨í„´ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
{dong_name}ì˜ ì‹œê°„ëŒ€ë³„ ì¸êµ¬ ë³€í™”ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì£¼ë¯¼ë“¤ì˜ ìƒí™œ íŒ¨í„´ì„ ë¶„ì„í•´ì£¼ì„¸ìš”.

ë°ì´í„°:
- ì•„ì¹¨ ì‹œê°„ëŒ€(06-09ì‹œ) ì¸êµ¬: {morning:,}ëª…
- ì˜¤í›„ ì‹œê°„ëŒ€(14-16ì‹œ) ì¸êµ¬: {afternoon:,}ëª…  
- ì‹¬ì•¼ ì‹œê°„ëŒ€(22-01ì‹œ) ì¸êµ¬: {night:,}ëª…
- ì´ ìƒì£¼ì¸êµ¬: {total:,}ëª…

ë¶„ì„ ê´€ì :
- ì£¼ê±°ì§€ì—­ vs ìƒì—…ì§€ì—­ vs ì—…ë¬´ì§€ì—­ íŠ¹ì„±
- ì§ì¥ì¸ vs í•™ìƒ vs ì£¼ë¶€ ì¤‘ì‹¬ ì§€ì—­
- ìœ ë™ì¸êµ¬ vs ìƒì£¼ì¸êµ¬ ë¹„ìœ¨
- í™œë™ ì‹œê°„ëŒ€ íŒ¨í„´
- ì§€ì—­ ë‚´ ì£¼ìš” ì‹œì„¤/ì¸í”„ë¼ ì˜í–¥

ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ **5ì¤„ ì´ë‚´**ë¡œ ê°„ê²°í•˜ê²Œ ë‹µë³€í•´ì£¼ì„¸ìš”:
"ì´ ì§€ì—­ì˜ ì£¼ìš” ìƒí™œ íŒ¨í„´ì€ "XXXí˜• ì§€ì—­"ì…ë‹ˆë‹¤. íŠ¹ì§•ìœ¼ë¡œëŠ” [íŒ¨í„´ ì„¤ëª… 2-3ê°€ì§€]ì´ë©°, ì´ëŠ” [ì§€ì—­ íŠ¹ì„±ê³¼ ì£¼ë¯¼ êµ¬ì„±ì— ëŒ€í•œ ë¶„ì„]ì„ ë³´ì—¬ì¤ë‹ˆë‹¤."
""")
    
    formatted_prompt = prompt.format(
        dong_name=dong_name,
        morning=int(morning_pop),
        afternoon=int(afternoon_pop),
        night=int(night_pop),
        total=int(float(population_data.get('total', 0)))
    )
    
    response = llm.invoke(formatted_prompt)
    lifestyle_analysis = response.content.strip()
    
    logger.info(f"ìƒí™œ íŒ¨í„´ ë¶„ì„ ì™„ë£Œ: {lifestyle_analysis[:50]}...")
    
    return {
        **state,
        "lifestyle_analysis": lifestyle_analysis,
        "current_step": "lifestyle_completed"
    }

def generate_overview_insights(state: OverviewInsightsState) -> OverviewInsightsState:
    """ìµœì¢… Overview ì¸ì‚¬ì´íŠ¸ ìƒì„±"""
    traffic_analysis = state.get("traffic_analysis", "")
    dining_analysis = state.get("dining_analysis", "")
    business_analysis = state.get("business_analysis", "")
    lifestyle_analysis = state.get("lifestyle_analysis", "")
    
    # ê° ë¶„ì„ì„ êµ¬ì¡°í™”ëœ í˜•íƒœë¡œ ë³€í™˜
    overview_insights = [
        {
            "type": "traffic",
            "title": "ğŸš¦ êµí†µ í˜¼ì¡ ì‹œê°„ëŒ€",
            "content": traffic_analysis,
            "icon": "ğŸš—"
        },
        {
            "type": "dining", 
            "title": "ğŸ½ï¸ ì¸ê¸° ë©”ë‰´ ì˜ˆì¸¡",
            "content": dining_analysis,
            "icon": "ğŸ¥˜"
        },
        {
            "type": "business",
            "title": "ğŸ’¼ ìœ ë§ ì‚¬ì—… ì•„ì´í…œ", 
            "content": business_analysis,
            "icon": "ğŸª"
        },
        {
            "type": "lifestyle",
            "title": "ğŸ  ìƒí™œ íŒ¨í„´ ë¶„ì„",
            "content": lifestyle_analysis,
            "icon": "â°"
        }
    ]
    
    logger.info(f"Overview ì¸ì‚¬ì´íŠ¸ ìƒì„± ì™„ë£Œ: {len(overview_insights)}ê°œ í•­ëª©")
    
    return {
        **state,
        "overview_insights": overview_insights,
        "current_step": "completed"
    }

## 3. LangGraph êµ¬ì„± ---------------------------------------------

def create_overview_insights_graph():
    """Overview Insights ìƒì„± ê·¸ë˜í”„ êµ¬ì„±"""
    
    # StateGraph ìƒì„±
    workflow = StateGraph(OverviewInsightsState)
    
    # ë…¸ë“œ ì¶”ê°€
    workflow.add_node("traffic_analysis", analyze_traffic_patterns)
    workflow.add_node("dining_analysis", analyze_dining_recommendations) 
    workflow.add_node("business_analysis", analyze_business_opportunities)
    workflow.add_node("lifestyle_analysis", analyze_lifestyle_patterns)
    workflow.add_node("generate_insights", generate_overview_insights)
    
    # ì—£ì§€ ì„¤ì • (ìˆœì°¨ ì‹¤í–‰)
    workflow.set_entry_point("traffic_analysis")
    workflow.add_edge("traffic_analysis", "dining_analysis")
    workflow.add_edge("dining_analysis", "business_analysis") 
    workflow.add_edge("business_analysis", "lifestyle_analysis")
    workflow.add_edge("lifestyle_analysis", "generate_insights")
    workflow.add_edge("generate_insights", END)
    
    return workflow.compile()

# ê·¸ë˜í”„ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
overview_graph = create_overview_insights_graph()

## 4. FastAPI ì—”ë“œí¬ì¸íŠ¸ ---------------------------------------------

@app.get("/health")
async def health_check():
    """ì„œë²„ ìƒíƒœ í™•ì¸"""
    return {
        "status": "healthy",
        "service": "Overview Insights Agent",
        "model": "gpt-4o-mini",
        "timestamp": datetime.now().isoformat()
    }

@app.post("/analyze/overview-insights")
async def generate_overview_insights_endpoint(data: Dict[str, Any]):
    """Overview ì‹¤ìš©ì  ì¸ì‚¬ì´íŠ¸ ìƒì„±"""
    
    try:
        dong_name = data.get('dongName', 'ì•Œ ìˆ˜ ì—†ëŠ” ë™')
        population_data = data.get('populationData', {})
        time_stats = data.get('timeStats', [])
        gender_stats = data.get('genderStats', {})
        age_stats = data.get('ageStats', [])
        
        logger.info(f"{dong_name} Overview ì¸ì‚¬ì´íŠ¸ ìƒì„± ì‹œì‘...")
        logger.info(f"ë°›ì€ ì¸êµ¬ ë°ì´í„°: {population_data}")
        logger.info(f"ë°›ì€ ì‹œê°„ëŒ€ ë°ì´í„° ê°œìˆ˜: {len(time_stats) if time_stats else 0}")
        
        # ì´ˆê¸° ìƒíƒœ ì„¤ì •
        initial_state: OverviewInsightsState = {
            "dong_name": dong_name,
            "population_data": population_data,
            "time_stats": time_stats,
            "gender_stats": gender_stats,
            "age_stats": age_stats,
            "traffic_analysis": "",
            "dining_analysis": "",
            "business_analysis": "",
            "lifestyle_analysis": "",
            "overview_insights": [],
            "current_step": "started"
        }
        
        # LangGraph ì‹¤í–‰
        final_state = overview_graph.invoke(initial_state)
        
        logger.info(f"{dong_name} Overview ì¸ì‚¬ì´íŠ¸ ìƒì„± ì™„ë£Œ")
        
        return {
            "dong_name": dong_name,
            "insights": final_state["overview_insights"],
            "status": "completed",
            "timestamp": datetime.now().isoformat()
        }
        
    except Exception as e:
        logger.error(f"Overview ì¸ì‚¬ì´íŠ¸ ìƒì„± ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail=f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

if __name__ == "__main__":
    import uvicorn
    logger.info(f"Overview Insights Agent ì„œë²„ ì‹œì‘: {HOST}:{PORT}")
    uvicorn.run(app, host=HOST, port=PORT)
