####### Overview ì‹¤ìš©ì  ì¸ì‚¬ì´íŠ¸ ìƒì„± Agent #######
## LangGraphë¥¼ í™œìš©í•œ ë‹¨ê³„ë³„ ë¶„ì„ ë° ì‹¤ìš©ì  ì¡°ì–¸ ìƒì„±

import pandas as pd
import numpy as np
import os
import random
from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from datetime import datetime
from typing import List, Dict, Any, Literal, TypedDict
import json
import logging
import warnings
from dotenv import load_dotenv

# .env íŒŒì¼ ë¡œë“œ
load_dotenv()

warnings.filterwarnings("ignore", category=DeprecationWarning)

from typing import Annotated, Literal, Sequence, TypedDict, List, Dict
from langchain import hub
from langchain_core.messages import BaseMessage, HumanMessage
from langchain_core.output_parsers import StrOutputParser
from langchain_core.prompts import ChatPromptTemplate
from langchain_openai import ChatOpenAI
from langchain_community.embeddings import OpenAIEmbeddings
from langchain_community.vectorstores import Chroma
from langgraph.graph import StateGraph, END

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# í™˜ê²½ë³€ìˆ˜ì—ì„œ ì„¤ì • ë¡œë“œ
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
HOST = os.getenv("HOST", "0.0.0.0")
PORT = 8003  # Overview Insights ì „ìš© í¬íŠ¸
ENVIRONMENT = os.getenv("ENVIRONMENT", "development")

# API í‚¤ í™•ì¸
if not OPENAI_API_KEY:
    logger.error("OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .env íŒŒì¼ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
    raise ValueError("OPENAI_API_KEYê°€ í•„ìš”í•©ë‹ˆë‹¤.")

logger.info(f"Overview Insights Agent ì„œë²„ í™˜ê²½: {ENVIRONMENT}")
logger.info(f"OpenAI API í‚¤ ì„¤ì •ë¨: {'*' * 10}{OPENAI_API_KEY[-4:] if OPENAI_API_KEY else 'None'}")

app = FastAPI(title="Overview ì‹¤ìš©ì  ì¸ì‚¬ì´íŠ¸ ìƒì„± API", version="1.0.0")

# CORS ì„¤ì •
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # ì„ì‹œë¡œ ëª¨ë“  origin í—ˆìš©
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

## 1. ê°œë°œì ì§ì ‘ ê´€ë¦¬ RAG ì‹œìŠ¤í…œ ---------------------------------------------

# ë™ë³„ íŠ¹ì„± ì •ë³´ (ê°œë°œìê°€ ì§ì ‘ ê´€ë¦¬)
DONG_SPECIFIC_KNOWLEDGE = {
    "ì‹ ì‚¬ë™": {
        "location": "ê°•ë‚¨êµ¬ ë¶ë¶€, ì••êµ¬ì •ë™ê³¼ ì¸ì ‘",
        "characteristics": "ê³ ê¸‰ ì£¼ê±°ì§€ì—­, ëª…í’ˆ ì‡¼í•‘ê°€, ì¹´í˜ê±°ë¦¬",
        "business_environment": "ëª…í’ˆ ë¸Œëœë“œ ë§¤ì¥, ê³ ê¸‰ ì¹´í˜, ë¯¸ìš©ì‹¤, ì˜ë£Œê¸°ê´€",
        "transportation": "ì§€í•˜ì²  3í˜¸ì„  ì‹ ì‚¬ì—­, ë‹¤ìˆ˜ ë²„ìŠ¤ ì •ë¥˜ì¥",
        "demographics": "ê³ ì†Œë“ì¸µ, 30~50ëŒ€ ë¹„ì¤‘ ë†’ìŒ",
        "popular_areas": "ê°€ë¡œìˆ˜ê¸¸, ì‹ ì‚¬ì—­ ì£¼ë³€, ì••êµ¬ì •ë¡œ",
        "dining_trends": "ê³ ê¸‰ í•œì‹, ì´íƒˆë¦¬ì•ˆ, í”„ë Œì¹˜, ì¹´í˜",
        "business_opportunities": "ëª…í’ˆ ë¦¬ì…€, ê³ ê¸‰ ë¯¸ìš©ì‹¤, í”„ë¦¬ë¯¸ì—„ ì¹´í˜, ì˜ë£Œ ì„œë¹„ìŠ¤"
    },
    "ì—­ì‚¼ë™": {
        "location": "ê°•ë‚¨êµ¬ ì¤‘ì‹¬ë¶€, ê°•ë‚¨ì—­ê³¼ ì¸ì ‘",
        "characteristics": "IT ì—…ê³„ ì¤‘ì‹¬ì§€, ìŠ¤íƒ€íŠ¸ì—… ë°€ì§‘ì§€ì—­",
        "business_environment": "IT ê¸°ì—…, ìŠ¤íƒ€íŠ¸ì—…, ê³µìœ  ì˜¤í”¼ìŠ¤, êµìœ¡ê¸°ê´€",
        "transportation": "ì§€í•˜ì²  2í˜¸ì„  ê°•ë‚¨ì—­, 9í˜¸ì„  ì‹ ë…¼í˜„ì—­",
        "demographics": "20~30ëŒ€ IT ì¢…ì‚¬ì, ì™¸êµ­ì¸ ë¹„ì¤‘ ë†’ìŒ",
        "popular_areas": "ê°•ë‚¨ì—­, í…Œí—¤ë€ë¡œ, ìŠ¤íƒ€íŠ¸ì—… ê±°ë¦¬",
        "dining_trends": "ë¶„ì‹, ì»¤í”¼, ìƒëŸ¬ë“œ, ë‹¤êµ­ì  ìš”ë¦¬",
        "business_opportunities": "IT êµìœ¡, ê³µìœ  ì˜¤í”¼ìŠ¤, ì™¸êµ­ì¸ ëŒ€ìƒ ì„œë¹„ìŠ¤, ê±´ê°•ì‹"
    },
    "ì²­ë‹´ë™": {
        "location": "ê°•ë‚¨êµ¬ ë™ë¶€, ì‚¼ì„±ë™ê³¼ ì¸ì ‘",
        "characteristics": "ê³ ê¸‰ ì£¼ê±°ì§€ì—­, ì—”í„°í…Œì¸ë¨¼íŠ¸ ì—…ê³„ ì¤‘ì‹¬",
        "business_environment": "ì—”í„°í…Œì¸ë¨¼íŠ¸ ê¸°ì—…, ê³ ê¸‰ ë ˆìŠ¤í† ë‘, í´ëŸ½",
        "transportation": "ì§€í•˜ì²  7í˜¸ì„  ì²­ë‹´ì—­, ë²„ìŠ¤ ì •ë¥˜ì¥",
        "demographics": "ê³ ì†Œë“ì¸µ, ì—”í„°í…Œì¸ë¨¼íŠ¸ ì¢…ì‚¬ì, ì™¸êµ­ì¸",
        "popular_areas": "ì²­ë‹´ì—­, ì—”í„°í…Œì¸ë¨¼íŠ¸ ê±°ë¦¬, ê³ ê¸‰ ë ˆìŠ¤í† ë‘ê°€",
        "dining_trends": "ê³ ê¸‰ í•œì‹, ì¼ë³¸ì‹, ì´íƒˆë¦¬ì•ˆ, í´ëŸ½",
        "business_opportunities": "ì—”í„°í…Œì¸ë¨¼íŠ¸ ê´€ë ¨, ê³ ê¸‰ ë ˆìŠ¤í† ë‘, í´ëŸ½, ë¯¸ìš©ì‹¤"
    },
    "ì‚¼ì„±ë™": {
        "location": "ê°•ë‚¨êµ¬ ë™ë¶€, ì½”ì—‘ìŠ¤ëª° ì¸ì ‘",
        "characteristics": "ëŒ€ê¸°ì—… ë³¸ì‚¬ ë°€ì§‘ì§€ì—­, êµ­ì œë¬´ì—­ì„¼í„°",
        "business_environment": "ëŒ€ê¸°ì—… ë³¸ì‚¬, ë¬´ì—­íšŒì‚¬, í˜¸í…”, ì»¨ë²¤ì…˜ì„¼í„°",
        "transportation": "ì§€í•˜ì²  2í˜¸ì„  ì‚¼ì„±ì—­, 9í˜¸ì„  ë´‰ì€ì‚¬ì—­",
        "demographics": "30~50ëŒ€ ì§ì¥ì¸, ì™¸êµ­ì¸ ë¹„ì¦ˆë‹ˆìŠ¤ë§¨",
        "popular_areas": "ì½”ì—‘ìŠ¤ëª°, ì‚¼ì„±ì—­, ë¬´ì—­ì„¼í„°",
        "dining_trends": "ë¹„ì¦ˆë‹ˆìŠ¤ ëŸ°ì¹˜, ê³ ê¸‰ í•œì‹, ë‹¤êµ­ì  ìš”ë¦¬",
        "business_opportunities": "ë¹„ì¦ˆë‹ˆìŠ¤ ì„œë¹„ìŠ¤, ë¬´ì—­ ê´€ë ¨, í˜¸í…”, ì»¨í¼ëŸ°ìŠ¤"
    },
    "ì••êµ¬ì •ë™": {
        "location": "ê°•ë‚¨êµ¬ ë¶ë¶€, ì‹ ì‚¬ë™ê³¼ ì¸ì ‘",
        "characteristics": "ê³ ê¸‰ ì£¼ê±°ì§€ì—­, ëª…í’ˆ ì‡¼í•‘ê°€",
        "business_environment": "ëª…í’ˆ ë§¤ì¥, ê³ ê¸‰ ë ˆìŠ¤í† ë‘, ë¯¸ìš©ì‹¤",
        "transportation": "ì§€í•˜ì²  3í˜¸ì„  ì••êµ¬ì •ì—­",
        "demographics": "ê³ ì†Œë“ì¸µ, 40~60ëŒ€ ë¹„ì¤‘ ë†’ìŒ",
        "popular_areas": "ì••êµ¬ì •ë¡œë°ì˜¤, ëª…í’ˆ ê±°ë¦¬",
        "dining_trends": "ê³ ê¸‰ í•œì‹, ì´íƒˆë¦¬ì•ˆ, í”„ë Œì¹˜, ì¹´í˜",
        "business_opportunities": "ëª…í’ˆ ë¦¬ì…€, ê³ ê¸‰ ë¯¸ìš©ì‹¤, í”„ë¦¬ë¯¸ì—„ ì„œë¹„ìŠ¤"
    }
}

# ê°œë°œìê°€ ì§ì ‘ ì¶”ê°€í•  ìˆ˜ ìˆëŠ” ë™ë³„ ì •ë³´ (ì˜ˆì‹œ)
# ìƒˆë¡œìš´ ë™ì„ ì¶”ê°€í•˜ë ¤ë©´ ì•„ë˜ì— ì •ë³´ë¥¼ ì¶”ê°€í•˜ë©´ ë©ë‹ˆë‹¤
CUSTOM_DONG_KNOWLEDGE = {
    # ì˜ˆì‹œ: "ê°œí¬ë™": {
    #     "location": "ê°•ë‚¨êµ¬ ì„œë¶€, ëŒ€ì¹˜ë™ê³¼ ì¸ì ‘",
    #     "characteristics": "ì£¼ê±°ì§€ì—­, êµìœ¡ì—´ ë†’ìŒ",
    #     "business_environment": "í•™ì›ê°€, ì£¼ê±°ì‹œì„¤, í¸ì˜ì ",
    #     "transportation": "ì§€í•˜ì²  2í˜¸ì„  ê°œí¬ë™ì—­",
    #     "demographics": "í•™ìƒ, í•™ë¶€ëª¨, 30-50ëŒ€",
    #     "popular_areas": "ê°œí¬ë™ì—­, í•™ì›ê°€",
    #     "dining_trends": "í•™ìƒì‹ë‹¹, ë¶„ì‹, ì¹´í˜",
    #     "business_opportunities": "í•™ì›, ê³¼ì™¸, í•™ìƒ ëŒ€ìƒ ì„œë¹„ìŠ¤"
    # }
}

def get_dong_knowledge(dong_name: str) -> Dict[str, str]:
    """ë™ë³„ íŠ¹ì„± ì •ë³´ ì¡°íšŒ (ê°œë°œì ì§ì ‘ ê´€ë¦¬ RAG ì‹œìŠ¤í…œ)"""
    # ë™ ì´ë¦„ì—ì„œ 'ë™' ì œê±°í•˜ì—¬ ë§¤ì¹­
    clean_dong_name = dong_name.replace('ë™', '').replace(' ', '')
    
    # 1. ë¨¼ì € ê°œë°œìê°€ ì¶”ê°€í•œ ì»¤ìŠ¤í…€ ì •ë³´ì—ì„œ í™•ì¸
    for key, value in CUSTOM_DONG_KNOWLEDGE.items():
        if clean_dong_name in key or key in clean_dong_name:
            logger.info(f"{dong_name} ì»¤ìŠ¤í…€ ì •ë³´ ë¡œë“œë¨")
            return value
    
    # 2. ê¸°ë³¸ í•˜ë“œì½”ë”©ëœ ì •ë³´ì—ì„œ ë§¤ì¹­
    for key, value in DONG_SPECIFIC_KNOWLEDGE.items():
        if clean_dong_name in key or key in clean_dong_name:
            logger.info(f"{dong_name} ê¸°ë³¸ ì •ë³´ ë¡œë“œë¨")
            return value
    
    # 3. ê¸°ë³¸ ì •ë³´ (ë§¤ì¹­ë˜ì§€ ì•ŠëŠ” ê²½ìš°)
    logger.info(f"{dong_name} ê¸°ë³¸ ì •ë³´ ì‚¬ìš©")
    return {
        "location": "ê°•ë‚¨êµ¬ ë‚´ ìœ„ì¹˜",
        "characteristics": "ìƒì—…ì§€ì—­ê³¼ ì£¼ê±°ì§€ì—­ì´ í˜¼ì¬",
        "business_environment": "ë‹¤ì–‘í•œ ìƒì—…ì‹œì„¤ê³¼ ì£¼ê±°ì‹œì„¤",
        "transportation": "ì§€í•˜ì² ê³¼ ë²„ìŠ¤ ì •ë¥˜ì¥ ì ‘ê·¼ ê°€ëŠ¥",
        "demographics": "ë‹¤ì–‘í•œ ì—°ë ¹ëŒ€ì™€ ì§ì—…êµ°",
        "popular_areas": "ì£¼ìš” ìƒì—…ì§€ì—­",
        "dining_trends": "ë‹¤ì–‘í•œ ìŒì‹ì ê³¼ ì¹´í˜",
        "business_opportunities": "ë‹¤ì–‘í•œ ì‚¬ì—… ê¸°íšŒ"
    }

def add_custom_dong_knowledge(dong_name: str, knowledge: Dict[str, str]) -> bool:
    """ê°œë°œìê°€ ìƒˆë¡œìš´ ë™ ì •ë³´ë¥¼ ì¶”ê°€í•˜ëŠ” í•¨ìˆ˜"""
    try:
        clean_dong_name = dong_name.replace('ë™', '').replace(' ', '')
        CUSTOM_DONG_KNOWLEDGE[clean_dong_name] = knowledge
        logger.info(f"{dong_name} ì»¤ìŠ¤í…€ ì •ë³´ ì¶”ê°€ë¨")
        return True
    except Exception as e:
        logger.error(f"{dong_name} ì»¤ìŠ¤í…€ ì •ë³´ ì¶”ê°€ ì‹¤íŒ¨: {e}")
        return False

def get_all_dong_names() -> List[str]:
    """ë“±ë¡ëœ ëª¨ë“  ë™ ì´ë¦„ ëª©ë¡ ë°˜í™˜"""
    all_dongs = list(DONG_SPECIFIC_KNOWLEDGE.keys()) + list(CUSTOM_DONG_KNOWLEDGE.keys())
    return sorted(all_dongs)

## 2. State ì •ì˜ ---------------------------------------------
class OverviewInsightsState(TypedDict):
    dong_name: str
    population_data: Dict[str, Any]
    time_stats: List[Dict[str, Any]]
    gender_stats: Dict[str, Any] 
    age_stats: Dict[str, Any]
    
    # RAG ì»¨í…ìŠ¤íŠ¸
    dong_knowledge: Dict[str, str]  # ë™ë³„ íŠ¹ì„± ì •ë³´
    
    # ë‹¨ê³„ë³„ ë¶„ì„ ê²°ê³¼
    traffic_analysis: str      # êµí†µ í˜¼ì¡ ì‹œê°„ëŒ€ ë¶„ì„
    dining_analysis: str       # ì‹ë‹¹ ë©”ë‰´ ì¶”ì²œ ë¶„ì„
    business_analysis: str     # ì‚¬ì—… ì•„ì´í…œ ì¶”ì²œ ë¶„ì„
    lifestyle_analysis: str    # ìƒí™œ íŒ¨í„´ ë¶„ì„
    
    # ìµœì¢… ê²°ê³¼
    overview_insights: List[Dict[str, str]]  # [{type: "traffic", content: "..."}, ...]
    current_step: str

## 2. LangGraph Agent ë…¸ë“œë“¤ ---------------------------------------------

def analyze_traffic_patterns(state: OverviewInsightsState) -> OverviewInsightsState:
    """êµí†µ í˜¼ì¡ ì‹œê°„ëŒ€ ë¶„ì„"""
    dong_name = state.get("dong_name", "")
    time_stats = state.get("time_stats", [])
    dong_knowledge = state.get("dong_knowledge", {})
    
    llm = ChatOpenAI(model="gpt-4o-mini")
    
    # ì‹œê°„ëŒ€ë³„ ì¸êµ¬ ë°ì´í„° ì¤€ë¹„ (Double íƒ€ì… ì²˜ë¦¬)
    time_data_text = ""
    if time_stats and len(time_stats) > 0:
        sorted_times = sorted(time_stats, key=lambda x: float(x.get('totalPopulation', 0)), reverse=True)
        top_3_busy = sorted_times[:3]
        time_data_text = ", ".join([f"{t.get('timeRange', 'N/A')}ì‹œ({int(float(t.get('totalPopulation', 0))):,}ëª…)" for t in top_3_busy])
    
    # RAG ì»¨í…ìŠ¤íŠ¸ ì •ë³´
    rag_context = f"""
ì§€ì—­ íŠ¹ì„± ì •ë³´:
- ìœ„ì¹˜: {dong_knowledge.get('location', 'N/A')}
- íŠ¹ì„±: {dong_knowledge.get('characteristics', 'N/A')}
- êµí†µ: {dong_knowledge.get('transportation', 'N/A')}
- ì¸ê¸° ì§€ì—­: {dong_knowledge.get('popular_areas', 'N/A')}
"""
    
    prompt = ChatPromptTemplate.from_template("""
ë‹¹ì‹ ì€ ë„ì‹œ êµí†µ íŒ¨í„´ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
{dong_name}ì˜ ì‹œê°„ëŒ€ë³„ ì¸êµ¬ ë°ì´í„°ì™€ ì§€ì—­ íŠ¹ì„±ì„ ë°”íƒ•ìœ¼ë¡œ êµí†µ í˜¼ì¡ ì‹œê°„ëŒ€ë¥¼ ë¶„ì„í•´ì£¼ì„¸ìš”.

[ì§€ì—­ íŠ¹ì„± ì •ë³´]
{rag_context}

[ì‹œê°„ëŒ€ë³„ ì¸êµ¬ ë°ì´í„° (ìƒìœ„ 3ê°œ)]
{time_data}

êµ¬ì²´ì ì¸ ì´ìœ  ì˜ˆì‹œ:
- ì¶œê·¼/í‡´ê·¼ ëŸ¬ì‹œì•„ì›Œ
- ìƒì—…ì§€ì—­ íŠ¹ì„±ìƒ ì‡¼í•‘ê° ìœ ì…
- ì¸ê·¼ ì‚¬ë¬´ë¹Œë”©/í•™êµì˜ í™œë™ ì‹œê°„
- ì‹ë‹¹ê°€ ì´ìš©ê° ì§‘ì¤‘ ì‹œê°„
- ì§€ì—­ íŠ¹ì„±ì— ë”°ë¥¸ íŠ¹ë³„í•œ ìš”ì¸

ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ **3ì¤„ ì´ë‚´**ë¡œ ê°„ê²°í•˜ê²Œ ë‹µë³€í•´ì£¼ì„¸ìš”:
"êµí†µì´ ê°€ì¥ í˜¼ì¡í•œ ì‹œê°„ëŒ€ëŠ” "XX"ì‹œ ì…ë‹ˆë‹¤. ì´ëŠ” [êµ¬ì²´ì ì¸ ì´ìœ  1-2ê°€ì§€]ë¡œ ì¸í•´ ëŒ€ì¤‘êµí†µ ì´ìš©ëŸ‰ê³¼ ë„ë¡œ êµí†µëŸ‰ì´ ê¸‰ì¦í•˜ëŠ” ì‹œê°„ëŒ€ì…ë‹ˆë‹¤."
""")
    
    formatted_prompt = prompt.format(
        dong_name=dong_name,
        rag_context=rag_context,
        time_data=time_data_text or "ë°ì´í„° ì—†ìŒ"
    )
    
    response = llm.invoke(formatted_prompt)
    traffic_analysis = response.content.strip()
    
    logger.info(f"êµí†µ ë¶„ì„ ì™„ë£Œ: {traffic_analysis[:50]}...")
    
    return {
        **state,
        "traffic_analysis": traffic_analysis,
        "current_step": "traffic_completed"
    }

def analyze_dining_recommendations(state: OverviewInsightsState) -> OverviewInsightsState:
    """ì‹ë‹¹ ë©”ë‰´ ì¶”ì²œ ë¶„ì„"""
    dong_name = state.get("dong_name", "")
    time_stats = state.get("time_stats", [])
    gender_stats = state.get("gender_stats", {})
    age_stats = state.get("age_stats", [])
    dong_knowledge = state.get("dong_knowledge", {})
    
    llm = ChatOpenAI(model="gpt-4o-mini")
    
    # ì ì‹¬/ì €ë… ì‹œê°„ëŒ€ ë°ì´í„° ì¶”ì¶œ (Double íƒ€ì… ì²˜ë¦¬)
    lunch_data = [t for t in time_stats if any(hour in t.get('timeRange', '') for hour in ['11', '12', '13'])]
    dinner_data = [t for t in time_stats if any(hour in t.get('timeRange', '') for hour in ['17', '18', '19', '20', '21', '22'])]
    
    lunch_population = sum([float(t.get('totalPopulation', 0)) for t in lunch_data])
    dinner_population = sum([float(t.get('totalPopulation', 0)) for t in dinner_data])
    
    # ì„±ë³„/ì—°ë ¹ ì •ë³´ (Double íƒ€ì… ì²˜ë¦¬)
    male_count = float(gender_stats.get('male', 0))
    female_count = float(gender_stats.get('female', 0))
    total_count = float(gender_stats.get('total', 1)) if gender_stats.get('total', 0) > 0 else 1
    
    male_ratio = round(male_count / total_count * 100, 1)
    female_ratio = round(female_count / total_count * 100, 1)
    
    # RAG ì»¨í…ìŠ¤íŠ¸ ì •ë³´
    rag_context = f"""
ì§€ì—­ íŠ¹ì„± ì •ë³´:
- íŠ¹ì„±: {dong_knowledge.get('characteristics', 'N/A')}
- ì¸êµ¬ êµ¬ì„±: {dong_knowledge.get('demographics', 'N/A')}
- ì¸ê¸° ì§€ì—­: {dong_knowledge.get('popular_areas', 'N/A')}
- ì™¸ì‹ íŠ¸ë Œë“œ: {dong_knowledge.get('dining_trends', 'N/A')}
"""
    
    prompt = ChatPromptTemplate.from_template("""
ë‹¹ì‹ ì€ ì™¸ì‹ì—…ê³„ íŠ¸ë Œë“œ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
{dong_name}ì˜ ì¸êµ¬ êµ¬ì„±, ì‹ì‚¬ ì‹œê°„ëŒ€ ë°ì´í„°, ê·¸ë¦¬ê³  ì§€ì—­ íŠ¹ì„±ì„ ë°”íƒ•ìœ¼ë¡œ ì¸ê¸° ë©”ë‰´ë¥¼ ì˜ˆì¸¡í•´ì£¼ì„¸ìš”.

[ì§€ì—­ íŠ¹ì„± ì •ë³´]
{rag_context}

[ì¸êµ¬ ë°ì´í„°]
- ì ì‹¬ì‹œê°„(11-13ì‹œ) ìœ ë™ì¸êµ¬: {lunch_pop:,}ëª…
- ì €ë…ì‹œê°„(17-22ì‹œ) ìœ ë™ì¸êµ¬: {dinner_pop:,}ëª…  
- ì„±ë³„ ë¹„ìœ¨: ë‚¨ì„± {male_ratio}%, ì—¬ì„± {female_ratio}%

ë©”ë‰´ ì„ íƒ ì‹œ ê³ ë ¤ì‚¬í•­:
- ì„±ë³„ ë¹„ìœ¨ì— ë”°ë¥¸ ì„ í˜¸ë„
- ì§ì¥ì¸/í•™ìƒ/ì£¼ë¶€ ë“± ì£¼ ê³ ê°ì¸µ
- ì§€ì—­ íŠ¹ì„± (ìƒì—…ì§€/ì£¼ê±°ì§€/ì˜¤í”¼ìŠ¤ê°€)
- ê°€ê²©ëŒ€ì™€ ì ‘ê·¼ì„±
- ë°°ë‹¬/í¬ì¥ ê°€ëŠ¥ì„±
- ì§€ì—­ì˜ ì™¸ì‹ íŠ¸ë Œë“œì™€ íŠ¹ì„±

ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ **3ì¤„ ì´ë‚´**ë¡œ ê°„ê²°í•˜ê²Œ ë‹µë³€í•´ì£¼ì„¸ìš”:
"(ì„±ë³„, ë‚˜ì´ëŒ€ë¥¼ ê³ ë ¤í•˜ì—¬) ê°€ì¥ ì¸ê¸°ìˆì„ ê²ƒ ê°™ì€ ì ì‹¬(11ì‹œ~13ì‹œ) ë©”ë‰´ëŠ” "XXX"ì´ê³  ì €ë…(17ì‹œ~22ì‹œ) ë©”ë‰´ëŠ” "XXX"ì…ë‹ˆë‹¤. ì ì‹¬ ë©”ë‰´ ì„ íƒ ì´ìœ ëŠ” [êµ¬ì²´ì  ì´ìœ  1-2ê°€ì§€], ì €ë… ë©”ë‰´ ì„ íƒ ì´ìœ ëŠ” [êµ¬ì²´ì  ì´ìœ  1-2ê°€ì§€]ì…ë‹ˆë‹¤."
""")
    
    formatted_prompt = prompt.format(
        dong_name=dong_name,
        rag_context=rag_context,
        lunch_pop=int(lunch_population),
        dinner_pop=int(dinner_population),
        male_ratio=male_ratio,
        female_ratio=female_ratio
    )
    
    response = llm.invoke(formatted_prompt)
    dining_analysis = response.content.strip()
    
    logger.info(f"ì‹ë‹¹ ë©”ë‰´ ë¶„ì„ ì™„ë£Œ: {dining_analysis[:50]}...")
    
    return {
        **state,
        "dining_analysis": dining_analysis,
        "current_step": "dining_completed"
    }

def analyze_business_opportunities(state: OverviewInsightsState) -> OverviewInsightsState:
    """ì‚¬ì—… ì•„ì´í…œ ì¶”ì²œ ë¶„ì„"""
    dong_name = state.get("dong_name", "")
    population_data = state.get("population_data", {})
    time_stats = state.get("time_stats", [])
    gender_stats = state.get("gender_stats", {})
    dong_knowledge = state.get("dong_knowledge", {})
    
    llm = ChatOpenAI(model="gpt-4o-mini")
    
    # í”¼í¬ ì‹œê°„ëŒ€ ë¶„ì„ (Double íƒ€ì… ì²˜ë¦¬)
    peak_times = sorted(time_stats, key=lambda x: float(x.get('totalPopulation', 0)), reverse=True)[:2]
    peak_info = ", ".join([f"{t.get('timeRange', 'N/A')}ì‹œ" for t in peak_times])
    
    # ì™¸êµ­ì¸ ë¹„ìœ¨ (Double íƒ€ì… ì²˜ë¦¬)
    total_pop = float(population_data.get('total', 1)) if population_data.get('total', 0) > 0 else 1
    long_foreigner = float(population_data.get('longForeigner', 0))
    temp_foreigner = float(population_data.get('tempForeigner', 0))
    foreigner_ratio = round((long_foreigner + temp_foreigner) / total_pop * 100, 1)
    
    # RAG ì»¨í…ìŠ¤íŠ¸ ì •ë³´
    rag_context = f"""
ì§€ì—­ íŠ¹ì„± ì •ë³´:
- íŠ¹ì„±: {dong_knowledge.get('characteristics', 'N/A')}
- ì‚¬ì—… í™˜ê²½: {dong_knowledge.get('business_environment', 'N/A')}
- ì¸êµ¬ êµ¬ì„±: {dong_knowledge.get('demographics', 'N/A')}
- ì‚¬ì—… ê¸°íšŒ: {dong_knowledge.get('business_opportunities', 'N/A')}
"""
    
    prompt = ChatPromptTemplate.from_template("""
ë‹¹ì‹ ì€ ì°½ì—… ì»¨ì„¤íŒ… ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
{dong_name}ì˜ ì¸êµ¬ ë°ì´í„°ì™€ ì§€ì—­ íŠ¹ì„±ì„ ë°”íƒ•ìœ¼ë¡œ ìœ ë§í•œ ì‚¬ì—… ì•„ì´í…œì„ ì¶”ì²œí•´ì£¼ì„¸ìš”.

[ì§€ì—­ íŠ¹ì„± ì •ë³´]
{rag_context}

[ì¸êµ¬ ë°ì´í„°]
- ì´ ì¸êµ¬: {total:,}ëª…
- ì™¸êµ­ì¸ ë¹„ìœ¨: {foreigner_ratio}%
- ì„±ë³„ ë¹„ìœ¨: ë‚¨ì„± {male_ratio}%, ì—¬ì„± {female_ratio}%
- ì£¼ìš” í™œë™ ì‹œê°„ëŒ€: {peak_times}

ê³ ë ¤ ìš”ì†Œ:
- ì¸êµ¬ ë°€ë„ì™€ ìœ ë™ì¸êµ¬
- ì„±ë³„/ì—°ë ¹ êµ¬ì„±
- ì™¸êµ­ì¸ ë¹„ìœ¨ (ë‹¤ë¬¸í™” ì„œë¹„ìŠ¤ í•„ìš”ì„±)
- í”¼í¬ ì‹œê°„ëŒ€ (ì„œë¹„ìŠ¤ ì‹œê°„ ìµœì í™”)
- ì§€ì—­ íŠ¹ì„± (ìƒì—…/ì£¼ê±°/ì—…ë¬´)
- ì§€ì—­ì˜ ì‚¬ì—… í™˜ê²½ê³¼ ê¸°íšŒ

ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ **3ì¤„ ì´ë‚´**ë¡œ ê°„ê²°í•˜ê²Œ ë‹µë³€í•´ì£¼ì„¸ìš”:
"ì´ ì§€ì—­ì—ì„œ ê°€ì¥ ìœ ë§í•œ ì‚¬ì—… ì•„ì´í…œì€ "XXXì—…ì¢…"ì…ë‹ˆë‹¤. ì¶”ì²œ ì´ìœ ëŠ” [êµ¬ì²´ì  ê·¼ê±° 2-3ê°€ì§€]ì´ë©°, íŠ¹íˆ [íƒ€ê²Ÿ ê³ ê°ì¸µ]ì„ ëŒ€ìƒìœ¼ë¡œ í•œ [êµ¬ì²´ì  ì„œë¹„ìŠ¤/ìƒí’ˆ]ì´ ì„±ê³µ ê°€ëŠ¥ì„±ì´ ë†’ìŠµë‹ˆë‹¤."
""")
    
    male_ratio = round(float(gender_stats.get('male', 0)) / total_pop * 100, 1)
    female_ratio = round(float(gender_stats.get('female', 0)) / total_pop * 100, 1)
    
    formatted_prompt = prompt.format(
        dong_name=dong_name,
        rag_context=rag_context,
        total=int(total_pop),
        foreigner_ratio=foreigner_ratio,
        male_ratio=male_ratio,
        female_ratio=female_ratio,
        peak_times=peak_info
    )
    
    response = llm.invoke(formatted_prompt)
    business_analysis = response.content.strip()
    
    logger.info(f"ì‚¬ì—… ì•„ì´í…œ ë¶„ì„ ì™„ë£Œ: {business_analysis[:50]}...")
    
    return {
        **state,
        "business_analysis": business_analysis,
        "current_step": "business_completed"
    }

def analyze_lifestyle_patterns(state: OverviewInsightsState) -> OverviewInsightsState:
    """ìƒí™œ íŒ¨í„´ ë¶„ì„"""
    dong_name = state.get("dong_name", "")
    time_stats = state.get("time_stats", [])
    population_data = state.get("population_data", {})
    dong_knowledge = state.get("dong_knowledge", {})
    
    llm = ChatOpenAI(model="gpt-4o-mini")
    
    # ì‹œê°„ëŒ€ë³„ íŒ¨í„´ ë¶„ì„ (Double íƒ€ì… ì²˜ë¦¬)
    morning_pop = sum([float(t.get('totalPopulation', 0)) for t in time_stats if any(h in t.get('timeRange', '') for h in ['06', '07', '08', '09'])])
    afternoon_pop = sum([float(t.get('totalPopulation', 0)) for t in time_stats if any(h in t.get('timeRange', '') for h in ['14', '15', '16'])])
    night_pop = sum([float(t.get('totalPopulation', 0)) for t in time_stats if any(h in t.get('timeRange', '') for h in ['22', '23', '00', '01'])])
    
    # RAG ì»¨í…ìŠ¤íŠ¸ ì •ë³´
    rag_context = f"""
ì§€ì—­ íŠ¹ì„± ì •ë³´:
- íŠ¹ì„±: {dong_knowledge.get('characteristics', 'N/A')}
- ì¸êµ¬ êµ¬ì„±: {dong_knowledge.get('demographics', 'N/A')}
- ì¸ê¸° ì§€ì—­: {dong_knowledge.get('popular_areas', 'N/A')}
- ì‚¬ì—… í™˜ê²½: {dong_knowledge.get('business_environment', 'N/A')}
"""
    
    prompt = ChatPromptTemplate.from_template("""
ë‹¹ì‹ ì€ ë„ì‹œ ìƒí™œ íŒ¨í„´ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
{dong_name}ì˜ ì‹œê°„ëŒ€ë³„ ì¸êµ¬ ë³€í™”ì™€ ì§€ì—­ íŠ¹ì„±ì„ ë°”íƒ•ìœ¼ë¡œ ì£¼ë¯¼ë“¤ì˜ ìƒí™œ íŒ¨í„´ì„ ë¶„ì„í•´ì£¼ì„¸ìš”.

[ì§€ì—­ íŠ¹ì„± ì •ë³´]
{rag_context}

[ì‹œê°„ëŒ€ë³„ ì¸êµ¬ ë°ì´í„°]
- ì•„ì¹¨ ì‹œê°„ëŒ€(06-09ì‹œ) ì¸êµ¬: {morning:,}ëª…
- ì˜¤í›„ ì‹œê°„ëŒ€(14-16ì‹œ) ì¸êµ¬: {afternoon:,}ëª…  
- ì‹¬ì•¼ ì‹œê°„ëŒ€(22-01ì‹œ) ì¸êµ¬: {night:,}ëª…
- ì´ ìƒì£¼ì¸êµ¬: {total:,}ëª…

ë¶„ì„ ê´€ì :
- ì£¼ê±°ì§€ì—­ vs ìƒì—…ì§€ì—­ vs ì—…ë¬´ì§€ì—­ íŠ¹ì„±
- ì§ì¥ì¸ vs í•™ìƒ vs ì£¼ë¶€ ì¤‘ì‹¬ ì§€ì—­
- ìœ ë™ì¸êµ¬ vs ìƒì£¼ì¸êµ¬ ë¹„ìœ¨
- í™œë™ ì‹œê°„ëŒ€ íŒ¨í„´
- ì§€ì—­ ë‚´ ì£¼ìš” ì‹œì„¤/ì¸í”„ë¼ ì˜í–¥
- ì§€ì—­ì˜ íŠ¹ì„±ê³¼ ì¸êµ¬ êµ¬ì„±

ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ **3ì¤„ ì´ë‚´**ë¡œ ê°„ê²°í•˜ê²Œ ë‹µë³€í•´ì£¼ì„¸ìš”:
"ì´ ì§€ì—­ì˜ ì£¼ìš” ìƒí™œ íŒ¨í„´ì€ "XXXí˜• ì§€ì—­"ì…ë‹ˆë‹¤. íŠ¹ì§•ìœ¼ë¡œëŠ” [íŒ¨í„´ ì„¤ëª… 2-3ê°€ì§€]ì´ë©°, ì´ëŠ” [ì§€ì—­ íŠ¹ì„±ê³¼ ì£¼ë¯¼ êµ¬ì„±ì— ëŒ€í•œ ë¶„ì„]ì„ ë³´ì—¬ì¤ë‹ˆë‹¤."
""")
    
    formatted_prompt = prompt.format(
        dong_name=dong_name,
        rag_context=rag_context,
        morning=int(morning_pop),
        afternoon=int(afternoon_pop),
        night=int(night_pop),
        total=int(float(population_data.get('total', 0)))
    )
    
    response = llm.invoke(formatted_prompt)
    lifestyle_analysis = response.content.strip()
    
    logger.info(f"ìƒí™œ íŒ¨í„´ ë¶„ì„ ì™„ë£Œ: {lifestyle_analysis[:50]}...")
    
    return {
        **state,
        "lifestyle_analysis": lifestyle_analysis,
        "current_step": "lifestyle_completed"
    }

def generate_overview_insights(state: OverviewInsightsState) -> OverviewInsightsState:
    """ìµœì¢… Overview ì¸ì‚¬ì´íŠ¸ ìƒì„±"""
    traffic_analysis = state.get("traffic_analysis", "")
    dining_analysis = state.get("dining_analysis", "")
    business_analysis = state.get("business_analysis", "")
    lifestyle_analysis = state.get("lifestyle_analysis", "")
    
    # ê° ë¶„ì„ì„ êµ¬ì¡°í™”ëœ í˜•íƒœë¡œ ë³€í™˜
    overview_insights = [
        {
            "type": "traffic",
            "title": "ğŸš¦ êµí†µ í˜¼ì¡ ì‹œê°„ëŒ€",
            "content": traffic_analysis,
            "icon": "ğŸš—"
        },
        {
            "type": "dining", 
            "title": "ğŸ½ï¸ ì¸ê¸° ë©”ë‰´ ì˜ˆì¸¡",
            "content": dining_analysis,
            "icon": "ğŸ¥˜"
        },
        {
            "type": "business",
            "title": "ğŸ’¼ ìœ ë§ ì‚¬ì—… ì•„ì´í…œ", 
            "content": business_analysis,
            "icon": "ğŸª"
        },
        {
            "type": "lifestyle",
            "title": "ğŸ  ìƒí™œ íŒ¨í„´ ë¶„ì„",
            "content": lifestyle_analysis,
            "icon": "â°"
        }
    ]
    
    logger.info(f"Overview ì¸ì‚¬ì´íŠ¸ ìƒì„± ì™„ë£Œ: {len(overview_insights)}ê°œ í•­ëª©")
    
    return {
        **state,
        "overview_insights": overview_insights,
        "current_step": "completed"
    }

## 3. LangGraph êµ¬ì„± ---------------------------------------------

def create_overview_insights_graph():
    """Overview Insights ìƒì„± ê·¸ë˜í”„ êµ¬ì„±"""
    
    # StateGraph ìƒì„±
    workflow = StateGraph(OverviewInsightsState)
    
    # ë…¸ë“œ ì¶”ê°€
    workflow.add_node("traffic_analysis", analyze_traffic_patterns)
    workflow.add_node("dining_analysis", analyze_dining_recommendations) 
    workflow.add_node("business_analysis", analyze_business_opportunities)
    workflow.add_node("lifestyle_analysis", analyze_lifestyle_patterns)
    workflow.add_node("generate_insights", generate_overview_insights)
    
    # ì—£ì§€ ì„¤ì • (ìˆœì°¨ ì‹¤í–‰)
    workflow.set_entry_point("traffic_analysis")
    workflow.add_edge("traffic_analysis", "dining_analysis")
    workflow.add_edge("dining_analysis", "business_analysis") 
    workflow.add_edge("business_analysis", "lifestyle_analysis")
    workflow.add_edge("lifestyle_analysis", "generate_insights")
    workflow.add_edge("generate_insights", END)
    
    return workflow.compile()

# ê·¸ë˜í”„ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
overview_graph = create_overview_insights_graph()

## 4. FastAPI ì—”ë“œí¬ì¸íŠ¸ ---------------------------------------------

@app.get("/health")
async def health_check():
    """ì„œë²„ ìƒíƒœ í™•ì¸"""
    return {
        "status": "healthy",
        "service": "Overview Insights Agent",
        "model": "gpt-4o-mini",
        "rag_system": "ê°œë°œì ì§ì ‘ ê´€ë¦¬ RAG",
        "supported_dongs": get_all_dong_names(),
        "timestamp": datetime.now().isoformat()
    }

@app.get("/dong-knowledge/{dong_name}")
async def get_dong_knowledge_endpoint(dong_name: str):
    """íŠ¹ì • ë™ì˜ RAG ì •ë³´ ì¡°íšŒ"""
    try:
        knowledge = get_dong_knowledge(dong_name)
        return {
            "status": "success",
            "dong_name": dong_name,
            "knowledge": knowledge,
            "timestamp": datetime.now().isoformat()
        }
    except Exception as e:
        logger.error(f"{dong_name} RAG ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/dong-knowledge")
async def get_all_dong_knowledge():
    """ëª¨ë“  ë™ì˜ RAG ì •ë³´ ëª©ë¡ ì¡°íšŒ"""
    try:
        all_dongs = get_all_dong_names()
        dong_info = {}
        
        for dong_name in all_dongs:
            knowledge = get_dong_knowledge(dong_name)
            dong_info[dong_name] = knowledge
        
        return {
            "status": "success",
            "dong_count": len(all_dongs),
            "dong_names": all_dongs,
            "dong_knowledge": dong_info,
            "timestamp": datetime.now().isoformat()
        }
    except Exception as e:
        logger.error(f"ëª¨ë“  ë™ RAG ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/analyze/overview-insights")
async def generate_overview_insights_endpoint(data: Dict[str, Any]):
    """Overview ì‹¤ìš©ì  ì¸ì‚¬ì´íŠ¸ ìƒì„±"""
    
    try:
        dong_name = data.get('dongName', 'ì•Œ ìˆ˜ ì—†ëŠ” ë™')
        population_data = data.get('populationData', {})
        time_stats = data.get('timeStats', [])
        gender_stats = data.get('genderStats', {})
        age_stats = data.get('ageStats', [])
        
        logger.info(f"{dong_name} Overview ì¸ì‚¬ì´íŠ¸ ìƒì„± ì‹œì‘...")
        logger.info(f"ë°›ì€ ì¸êµ¬ ë°ì´í„°: {population_data}")
        logger.info(f"ë°›ì€ ì‹œê°„ëŒ€ ë°ì´í„° ê°œìˆ˜: {len(time_stats) if time_stats else 0}")
        
        # RAG ì»¨í…ìŠ¤íŠ¸ ì´ˆê¸°í™”
        dong_knowledge = get_dong_knowledge(dong_name)
        logger.info(f"{dong_name} RAG ì»¨í…ìŠ¤íŠ¸ ë¡œë“œ: {list(dong_knowledge.keys())}")
        
        # ì´ˆê¸° ìƒíƒœ ì„¤ì •
        initial_state: OverviewInsightsState = {
            "dong_name": dong_name,
            "population_data": population_data,
            "time_stats": time_stats,
            "gender_stats": gender_stats,
            "age_stats": age_stats,
            "dong_knowledge": dong_knowledge,  # RAG ì»¨í…ìŠ¤íŠ¸ ì¶”ê°€
            "traffic_analysis": "",
            "dining_analysis": "",
            "business_analysis": "",
            "lifestyle_analysis": "",
            "overview_insights": [],
            "current_step": "started"
        }
        
        # LangGraph ì‹¤í–‰
        final_state = overview_graph.invoke(initial_state)
        
        logger.info(f"{dong_name} Overview ì¸ì‚¬ì´íŠ¸ ìƒì„± ì™„ë£Œ")
        
        return {
            "dong_name": dong_name,
            "insights": final_state["overview_insights"],
            "status": "completed",
            "timestamp": datetime.now().isoformat()
        }
        
    except Exception as e:
        logger.error(f"Overview ì¸ì‚¬ì´íŠ¸ ìƒì„± ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail=f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

if __name__ == "__main__":
    import uvicorn
    logger.info("=== Overview ì‹¤ìš©ì  ì¸ì‚¬ì´íŠ¸ ìƒì„± Agent ì„œë²„ ì‹œì‘ ===")
    logger.info(f"ì„œë²„ ì£¼ì†Œ: http://{HOST}:{PORT}")
    logger.info(f"ëª¨ë¸: GPT-4o-mini")
    logger.info(f"RAG ì‹œìŠ¤í…œ: ê°œë°œì ì§ì ‘ ê´€ë¦¬ RAG")
    logger.info(f"ì§€ì› ë™: {', '.join(get_all_dong_names())}")
    logger.info(f"í™˜ê²½: {ENVIRONMENT}")
    uvicorn.run(app, host=HOST, port=PORT)
